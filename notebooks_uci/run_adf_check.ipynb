{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4befbbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/resha/Documents/Github/balancing_framework\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /mnt/c/Users/resha/Documents/Github/balancing_framework/\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from framework import run_measurements, viz\n",
    "from fracdiff import frac_diff_bestd\n",
    "from monash_data_utils import convert_tsf_to_dataframe, monash_df_to_gluonts_train_datasets\n",
    "import os\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def run_adf(series):\n",
    "    adf_chunk_size = 100_000\n",
    "    num_stat = (0,0) # number of stationary windows, total number of windows\n",
    "    p_values = []\n",
    "    for i in range(0, len(series), adf_chunk_size):\n",
    "        data_chunk = series.dropna()[i:i+adf_chunk_size]\n",
    "        if data_chunk.nunique()==1:\n",
    "            print(f'series has only one unique value: {series.iloc[0]}')\n",
    "            continue\n",
    "        adf_result = adfuller(data_chunk) \n",
    "        # print(f'{i} p-value={adf_result[1]}, lags={adf_result[2]}')\n",
    "        num_stat = (num_stat[0], num_stat[1]+1)\n",
    "        p_values.append(adf_result[1])\n",
    "        if adf_result[1] < 0.05:\n",
    "            num_stat = (num_stat[0]+1, num_stat[1])\n",
    "    # if more than 50% of the p-values are above 0.05, then the data is not stationary\n",
    "    stationary = num_stat[0] >= num_stat[1]/2\n",
    "    return stationary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "368075b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes['holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "374a7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48143 NaNs were imputed out of 48143 total NaNs\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48204 entries, 0 to 48203\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   holiday              61 non-null     object \n",
      " 1   temp                 48204 non-null  float64\n",
      " 2   rain_1h              48204 non-null  float64\n",
      " 3   snow_1h              48204 non-null  float64\n",
      " 4   clouds_all           48204 non-null  int64  \n",
      " 5   weather_main         48204 non-null  object \n",
      " 6   weather_description  48204 non-null  object \n",
      " 7   date_time            48204 non-null  object \n",
      " 8   traffic_volume       48204 non-null  int64  \n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 3.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "dataset = fetch_ucirepo(id=492) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = dataset.data.features \n",
    "y = dataset.data.targets \n",
    "\n",
    "# Concatenate features and targets into a single DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Step 1: Replace '?' with NaN across the entire DataFrame\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Step 2: Convert data columns to a numeric type, excluding Date and Time\n",
    "for col in df.columns:\n",
    "    if col in ['date', 'Time', 'DateTime', 'date_time'] or df[col].dtype == 'O': continue\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "# Step 3: Combine Date and Time into a single datetime index\n",
    "# df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time']) # dayfirst=True\n",
    "# df.set_index('datetime', inplace=True)\n",
    "# df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "\n",
    "# Step 4: Impute the missing values\n",
    "# We will use linear interpolation, which is a good choice for continuous time series data.\n",
    "# This method fills a gap by drawing a straight line between the known values before and after the NaN.\n",
    "\n",
    "# print(\"\\nNumber of NaNs before interpolation:\")\n",
    "# print(df.isnull().sum())\n",
    "nansbef = df.isnull().sum().sum()\n",
    "df.interpolate(method='linear', inplace=True)\n",
    "# You can also use other methods:\n",
    "# df.fillna(method='ffill', inplace=True) # Forward fill\n",
    "# Verify the result\n",
    "# print(\"DataFrame info after interpolation:\")\n",
    "# print(\"\\nNumber of NaNs after interpolation:\")\n",
    "# print(df.isnull().sum())\n",
    "print(f'{df.isnull().sum().sum()} NaNs were imputed out of {nansbef} total NaNs')\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf89614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c0592e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp True\n",
      "rain_1h True\n",
      "snow_1h True\n",
      "clouds_all True\n",
      "traffic_volume True\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'O': continue\n",
    "    print(col, run_adf(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae488e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
