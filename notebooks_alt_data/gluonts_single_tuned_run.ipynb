{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /mnt/c/Users/resha/Documents/Github/balancing_framework/\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import optuna\n",
    "import argparse\n",
    "\n",
    "\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "from gluonts.mx.trainer import Trainer\n",
    "from gluonts.mx.trainer.callback import TrainingHistory\n",
    "from gluonts.mx.distribution import StudentTOutput, MultivariateGaussianOutput\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "\n",
    "from gluonts.mx.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.mx.model.transformer import TransformerEstimator\n",
    "from gluonts.mx.model.deepar import DeepAREstimator \n",
    "from gluonts.mx.model.wavenet import WaveNetEstimator\n",
    "from gluonts.mx.model.seq2seq import MQCNNEstimator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.dataset.common import ListDataset\n",
    "import copy\n",
    "\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "\n",
    "from gluonts_utils import series_to_gluonts_dataset, load_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3158ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Objective:\n",
    "    def __init__( self, model, dataset_name, X):\n",
    "        self.model = model\n",
    "        self.dataset_name = dataset_name\n",
    "        self.data_params = load_params('gluonts_params.txt', dataset_name)\n",
    "\n",
    "        predlen = self.data_params['prediction_length']\n",
    "        X_train_val, X_test = X[:-predlen], X[-predlen:]\n",
    "        X_train, X_val = X_train_val[:-predlen], X_train_val[-predlen:]\n",
    "        \n",
    "        self.tuning_dataset = series_to_gluonts_dataset(X_train, X_val,  self.data_params)\n",
    "        self.eval_dataset =  series_to_gluonts_dataset(X_train_val, X_test,  self.data_params)\n",
    "        \n",
    "\n",
    "    def get_params(self, trial) -> dict:\n",
    "        if self.model == 'feedforward':\n",
    "            return {\n",
    "              \"num_hidden_dimensions\": [trial.suggest_int(\"hidden_dim_{}\".format(i), 10, 100) for i in range(trial.suggest_int(\"num_layers\", 1, 5))],\n",
    "              \"trainer:learning_rate\": trial.suggest_loguniform(\"trainer:learning_rate\", 1e-6, 1e-3),\n",
    "              \"trainer:epochs\": trial.suggest_int(\"trainer:epochs\", 10, 100),\n",
    "            }\n",
    "        elif self.model == 'wavenet':\n",
    "            return {\n",
    "                \"trainer:learning_rate\": trial.suggest_loguniform(\"trainer:learning_rate\", 1e-6, 1e-3),\n",
    "                \"trainer:epochs\": trial.suggest_int(\"trainer:epochs\", 10, 100),\n",
    "            }\n",
    "        elif self.model == 'mqcnn':\n",
    "            return {\n",
    "                \"trainer:learning_rate\": trial.suggest_loguniform(\"trainer:learning_rate\", 1e-6, 1e-3),\n",
    "                \"trainer:epochs\": trial.suggest_int(\"trainer:epochs\", 10, 100),\n",
    "            }\n",
    "        elif self.model == 'deepar':\n",
    "            return {\n",
    "                \"num_cells\": trial.suggest_int(\"num_cells\", 10, 100),\n",
    "                \"num_layers\": trial.suggest_int(\"num_layers\", 1, 10),\n",
    "                \"trainer:learning_rate\": trial.suggest_loguniform(\"trainer:learning_rate\", 1e-6, 1e-3),\n",
    "                \"trainer:epochs\": trial.suggest_int(\"trainer:epochs\", 10, 100)\n",
    "            }\n",
    "        elif self.model == 'transformer':\n",
    "            # num_heads must divide model_dim\n",
    "            valid_pairs = [ (i,d) for i in range(10,101) for d in range(1,11) if i%d == 0  ]\n",
    "            model_dim_num_heads_pair = trial.suggest_categorical(\"model_dim_num_heads_pair\", valid_pairs)\n",
    "\n",
    "            return {\n",
    "                \"inner_ff_dim_scale\": trial.suggest_int(\"inner_ff_dim_scale\", 1, 5),\n",
    "                \"model_dim\": model_dim_num_heads_pair[0],\n",
    "                \"embedding_dimension\": trial.suggest_int(\"embedding_dimension\", 1, 10),\n",
    "                \"num_heads\": model_dim_num_heads_pair[1],\n",
    "                \"dropout_rate\": trial.suggest_uniform(\"dropout_rate\", 0.0, 0.5),\n",
    "                \"trainer:learning_rate\": trial.suggest_loguniform(\"trainer:learning_rate\", 1e-6, 1e-3),\n",
    "                \"trainer:epochs\": trial.suggest_int(\"trainer:epochs\", 10, 100),\n",
    "            }\n",
    "        \n",
    "    def load_model(self, params):\n",
    "        history = TrainingHistory()\n",
    "        if self.model == 'feedforward':\n",
    "            estimator = SimpleFeedForwardEstimator(\n",
    "                num_hidden_dimensions= params['num_hidden_dimensions'], #num_hidden_dimensions,\n",
    "                prediction_length=self.prediction_length,\n",
    "                context_length=self.context_length,\n",
    "                batch_normalization=False,\n",
    "                mean_scaling=False,\n",
    "                trainer=Trainer(ctx=self.ctx,epochs=params['trainer:epochs'], learning_rate=params['trainer:learning_rate'],\n",
    "                                num_batches_per_epoch=100, callbacks=[history]),\n",
    "            )\n",
    "        elif self.model == 'wavenet':\n",
    "            estimator = WaveNetEstimator(\n",
    "                freq=self.freq,\n",
    "                prediction_length=self.prediction_length,\n",
    "                trainer=Trainer(ctx=self.ctx,epochs=params['trainer:epochs'], learning_rate=params['trainer:learning_rate'],\n",
    "                                    num_batches_per_epoch=100, callbacks=[history], add_default_callbacks=False),\n",
    "            )\n",
    "        elif self.model == 'mqcnn':\n",
    "            estimator = MQCNNEstimator(\n",
    "                freq=self.freq,\n",
    "                prediction_length=self.prediction_length,\n",
    "                context_length=self.context_length,\n",
    "                distr_output=StudentTOutput(),\n",
    "                quantiles=None,\n",
    "                scaling=False, \n",
    "                trainer=Trainer(ctx=self.ctx,epochs=params['trainer:epochs'], learning_rate=params['trainer:learning_rate'],\n",
    "                                num_batches_per_epoch=100, callbacks=[history], hybridize=False),\n",
    "            )\n",
    "        elif self.model == 'deepar':\n",
    "            estimator = DeepAREstimator(\n",
    "                freq=self.freq,\n",
    "                context_length=self.context_length,\n",
    "                distr_output=StudentTOutput(),\n",
    "                prediction_length=self.prediction_length,\n",
    "                # num_cells= params['num_cells'],\n",
    "                # num_layers= params['num_layers'],\n",
    "                scaling=False, # True by default\n",
    "                trainer=Trainer(ctx=self.ctx,epochs=params['trainer:epochs'], learning_rate=params['trainer:learning_rate'],\n",
    "                                num_batches_per_epoch=100, callbacks=[history]),\n",
    "            )\n",
    "        elif self.model == 'transformer':\n",
    "            estimator = TransformerEstimator(\n",
    "                freq=self.freq,\n",
    "                context_length=self.context_length,\n",
    "                prediction_length=self.prediction_length,\n",
    "                distr_output=StudentTOutput(),\n",
    "                inner_ff_dim_scale= params['inner_ff_dim_scale'],\n",
    "                model_dim= params['model_dim'],\n",
    "                embedding_dimension= params['embedding_dimension'],\n",
    "                num_heads= params['num_heads'],\n",
    "                dropout_rate= params['dropout_rate'],\n",
    "                # scaling=False, # True by default False\n",
    "                trainer=Trainer(ctx=self.ctx,epochs=params['trainer:epochs'], learning_rate=params['trainer:learning_rate'],\n",
    "                                num_batches_per_epoch=100, callbacks=[history]),\n",
    "            )\n",
    "\n",
    "        return estimator, history\n",
    "\n",
    "    def train_test(self, params, tuning=True):\n",
    "        model, history = self.load_model(params)\n",
    "\n",
    "        if tuning:\n",
    "            predictor = model.train(self.tuning_dataset.train, self.tuning_dataset.test)\n",
    "            forecast_it, ts_it = make_evaluation_predictions(\n",
    "                dataset=self.tuning_dataset.test,\n",
    "                predictor=predictor,\n",
    "            )\n",
    "        else:\n",
    "            predictor = model.train(self.eval_dataset.train)\n",
    "            forecast_it, ts_it = make_evaluation_predictions(\n",
    "                dataset=self.eval_dataset.test,\n",
    "                predictor=predictor,\n",
    "            )\n",
    "\n",
    "        forecasts = list(forecast_it)\n",
    "        tss = list(ts_it)\n",
    "        evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "        agg_metrics, item_metrics = evaluator(tss, forecasts)\n",
    "        \n",
    "        print(f'#####__tuning mase = {agg_metrics[\"MASE\"]}__###### ')\n",
    "        return agg_metrics, predictor, history\n",
    "        \n",
    "\n",
    "    def __call__(self, trial):\n",
    "\n",
    "        params = self.get_params(trial)\n",
    "\n",
    "        agg_metrics, _, _ = self.train_test(params, tuning=True)\n",
    "\n",
    "        return agg_metrics['MASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a699fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('m4_1165.csv')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54561dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'm4_daily_dataset'\n",
    "model = 'transformer'\n",
    "save_label = 'original'\n",
    "n_trials = 1 #10\n",
    "n_repeats = 1 #5\n",
    "X = pd.read_csv('m4_1165.csv')\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# run tuning\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "obj = Objective(\n",
    "    model=model,\n",
    "    dataset_name=dataset_name,\n",
    "    X=X\n",
    "    )\n",
    "study.optimize(\n",
    "    obj,\n",
    "    n_trials=n_trials,\n",
    ")\n",
    "trial = study.best_trial\n",
    "\n",
    "# print results\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "print(f'Runtime: {time.perf_counter() - start_time}')\n",
    "\n",
    "# unpack params for next runs\n",
    "if model == 'feedforward':\n",
    "    trial.params[\"num_hidden_dimensions\"] = [ trial.params[f\"hidden_dim_{i}\"] for i in range(trial.params[\"num_layers\"]) ]\n",
    "elif model == 'transformer':\n",
    "    trial.params[\"model_dim\"] = trial.params[\"model_dim_num_heads_pair\"][0]\n",
    "    trial.params[\"num_heads\"] = trial.params[\"model_dim_num_heads_pair\"][1]\n",
    "\n",
    "# repeat best run 5 times\n",
    "mases = []\n",
    "smapes = []\n",
    "params_sets = []\n",
    "save_dir = f'results/monash_gluonts_single_tuned_runs/{model}_{dataset_name}_{save_label}_{n_trials}_trials'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for i in range(n_repeats):\n",
    "    res, predictor, history = obj.train_test(trial.params, tuning=False)\n",
    "\n",
    "    # plot and save training history\n",
    "    plt.plot(history.loss_history, label='Training Loss')\n",
    "    plt.plot(history.validation_loss_history, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'{save_dir}/learning_curve_{i}.png')\n",
    "    # save the history values\n",
    "    with open(f'{save_dir}/loss_history_{i}.json', \"w\") as f:\n",
    "        json.dump(history.loss_history, f)\n",
    "    # Clear the current figure\n",
    "    plt.clf()\n",
    "    mases.append(res['MASE'])\n",
    "    smapes.append(res['sMAPE'])\n",
    "    params_sets.append(trial.params)\n",
    "\n",
    "\n",
    "mase_mean = np.array(mases).mean()\n",
    "mase_std = np.std(np.array(mases))\n",
    "smape_mean = np.array(smapes).mean()\n",
    "smape_std = np.std(np.array(smapes))\n",
    "\n",
    "print(f'##### MASE MEAN: {mase_mean} MASE STD: {mase_std}')\n",
    "print(f'##### sMAPE MEAN: {smape_mean} sMAPE STD: {smape_std}')\n",
    "\n",
    "trial.params[\"mase_mean\"] = mase_mean\n",
    "trial.params[\"mase_std\"] = mase_std\n",
    "trial.params[\"smape_mean\"] = smape_mean\n",
    "trial.params[\"smape_std\"] = smape_std\n",
    "# save best params to json\n",
    "with open(f'{save_dir}/params.json', \"w\") as f:\n",
    "    json.dump(trial.params, f)\n",
    "\n",
    "# save the last predictor\n",
    "os.makedirs(f'{save_dir}/predictor', exist_ok=True)\n",
    "predictor.serialize(Path(f\"{save_dir}/predictor\"))\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "runtime = (end_time - start_time) / 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
