{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15119e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/mnt/c/Users/resha/Documents/Github/balancing_framework\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /mnt/c/Users/resha/Documents/Github/balancing_framework/\n",
    "\n",
    "from gluonts.dataset.repository import get_dataset, dataset_names\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from framework import run_measurements, viz\n",
    "from fracdiff import frac_diff_bestd\n",
    "from monash_data_utils import convert_tsf_to_dataframe, monash_df_to_gluonts_train_datasets\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f637c86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1166/4227 [00:00<00:00, 1064321.75it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(f\"Available datasets: {dataset_names}\")\n",
    "dataset = None\n",
    "monash_dir = \"monash_data\"\n",
    "series_num = -1\n",
    "\n",
    "# dataset_name = 'london_smart_meters_without_missing' # m4_daily_dataset ; london_smart_meters_without_missing\n",
    "# series_to_pull = 867 # m4, 1165 ; london, 1610 867\n",
    "dataset_name = 'm4_daily_dataset' # m4_daily_dataset ; london_smart_meters_without_missing\n",
    "series_to_pull = 1165 # m4, 1165 ; london, 1610 867\n",
    "\n",
    "if os.path.exists(f\"{monash_dir}/{dataset_name}.tsf\"):\n",
    "    loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(f\"{monash_dir}/{dataset_name}.tsf\")\n",
    "    if forecast_horizon is None: forecast_horizon = 24\n",
    "    dataset = monash_df_to_gluonts_train_datasets(loaded_data, frequency, forecast_horizon)\n",
    "\n",
    "if dataset is None:\n",
    "    if dataset_name in dataset_names:\n",
    "        dataset = get_dataset(dataset_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {dataset_name} not found in gluonts availables or local monash files.\")\n",
    "\n",
    "for entry in tqdm(dataset.test):\n",
    "    series_num += 1\n",
    "    if series_num > series_to_pull:\n",
    "        break\n",
    "    if series_num != series_to_pull:\n",
    "        continue\n",
    "    row = pd.Series(entry['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d34fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_row = row.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f86127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 stationary with d=0.9500000000000001 thresh=0.01 stat windows =1 out of 1 p-values = [0.006812139404067202]\n",
      "changed 1 out of 1 columns; 100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_fd, fd_change_pct = frac_diff_bestd(row.to_frame() )\n",
    "df_fd.dropna(inplace=True)\n",
    "df_fd.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2362b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_weights(diff_amt, size):\n",
    "    # The algorithm below executes the iterative estimation (section 5.4.2, page 78)\n",
    "    weights = [1.]  # create an empty list and initialize the first element with 1.\n",
    "    for k in range(1, size):\n",
    "        weights_ = -weights[-1] * (diff_amt - k + 1) / k  # compute the next weight\n",
    "        weights.append(weights_)\n",
    "\n",
    "    # Now, reverse the list, convert into a numpy column vector\n",
    "    weights = np.array(weights[::-1]).reshape(-1, 1)\n",
    "    return weights\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def frac_undiff(y_df, diff_amt, init_history, thresh=0.01):\n",
    "    # prepare weights\n",
    "    n = y_df.shape[0] + (0 if getattr(init_history, \"shape\", (None,))[0] is None else init_history.shape[0])\n",
    "    weights_full = np.asarray(get_weights(diff_amt, n)).ravel()\n",
    "\n",
    "    # compute skip\n",
    "    cum = np.cumsum(np.abs(weights_full))\n",
    "    cum /= cum[-1]\n",
    "    skip = int(cum[cum > thresh].shape[0])\n",
    "\n",
    "    # normalize init_history to DataFrame with correct columns\n",
    "    if isinstance(init_history, dict):\n",
    "        init_df = pd.concat({k: pd.Series(v).squeeze() for k, v in init_history.items()}, axis=1)\n",
    "    else:\n",
    "        init_df = init_history.copy()\n",
    "    if init_df.shape[0] != skip:\n",
    "        # allow full original series: take its first 'skip' rows\n",
    "        if init_df.shape[0] > skip:\n",
    "            init_df = init_df.iloc[:skip]\n",
    "        else:\n",
    "            raise ValueError(f\"init_history must have at least {skip} rows; got {init_df.shape[0]}\")\n",
    "\n",
    "    cols = y_df.columns\n",
    "    combined_index = list(init_df.index) + list(y_df.index)\n",
    "    x_rec = pd.DataFrame(index=combined_index, columns=cols, dtype='float64')\n",
    "\n",
    "    # fill initial history (ensure scalars)\n",
    "    for col in cols:\n",
    "        if col not in init_df:\n",
    "            raise ValueError(f\"Initial history missing column {col}\")\n",
    "        vals = np.asarray(init_df[col]).ravel()\n",
    "        x_rec.loc[init_df.index, col] = vals\n",
    "\n",
    "    # sequential inversion\n",
    "    for col in cols:\n",
    "        for t in y_df.index:\n",
    "            idx = combined_index.index(t)\n",
    "            t_step = idx\n",
    "            w = weights_full[: t_step + 1]  # 1-D\n",
    "            acc = 0.0\n",
    "            for k in range(1, len(w)):\n",
    "                prev_idx = idx - k\n",
    "                acc += float(w[k]) * float(x_rec.iat[prev_idx, x_rec.columns.get_loc(col)])\n",
    "            rhs = float(y_df.at[t, col]) - acc\n",
    "            x_rec.iat[idx, x_rec.columns.get_loc(col)] = rhs / float(w[0])\n",
    "\n",
    "    return x_rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots, arranged vertically\n",
    "# The sharex=True argument ensures both plots share the same x-axis for easier comparison\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=False)\n",
    "\n",
    "# Plot the first series on the top subplot (ax1)\n",
    "ax1.plot(df_fd[0],color='b')\n",
    "ax1.set_title('M4 Daily Series 1165 (FD)', fontsize=14)\n",
    "ax1.set_ylabel('Original Value', fontsize=12)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot the second series on the bottom subplot (ax2)\n",
    "ax2.plot(london_row, color='r')\n",
    "ax2.set_title('London Series 867', fontsize=14)\n",
    "ax2.set_xlabel('Index', fontsize=12)\n",
    "ax2.set_ylabel('Original Value', fontsize=12)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Adjust the layout to prevent titles and labels from overlapping\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'compare_series.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9584b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb108468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbde3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5ec62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
